{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "xgboost_model = XGBClassifier()\n",
    "xgboost_model.load_model(\"../3.Clasification/xgboost_final_model_Azure.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Preprocess features and compute embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para limpiar/calcular embeddings\n",
    "from clean_asr_service import CleanASRService\n",
    "cleanASRservice = CleanASRService()\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"\"\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_key = \"\"\n",
    "\n",
    "# Embeddings\n",
    "def compute_embeddings(df) :\n",
    "    df[\"embeddings\"] = df[\"cleaned_asr\"].apply(lambda x: get_embedding_azure(x, embedding_model=\"\"))\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_embedding_azure(text, embedding_model):\n",
    "    response = openai.Embedding.create(\n",
    "        input=text,\n",
    "        engine=embedding_model,\n",
    "        deployment_id = \"\"\n",
    "    )\n",
    "    return response['data'][0]['embedding']\n",
    "\n",
    "\n",
    "# Suffix/flow/asr_len\n",
    "# Preprocess data\n",
    "# Suffix column\n",
    "def get_suffix_from_intent(intent: str) -> str:\n",
    "    return norm_str(intent.split(\"-\")[-1].strip())\n",
    "\n",
    "def get_flow_from_intent(intent: str) -> str:\n",
    "    return norm_str(intent.split(\"-\")[0].strip())\n",
    "\n",
    "def norm_str(x:str) -> str:\n",
    "    return x.lower().strip()\n",
    "\n",
    "def compute_asr_len(asr: str) -> int:\n",
    "    try: \n",
    "        n_words = len(set(norm_str(asr).split()))\n",
    "    except:\n",
    "        n_words = 0\n",
    "    return n_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Request \n",
    "\n",
    "df = pd.DataFrame(request)\n",
    "\n",
    "#### Feature preprocessing ####\n",
    "df[\"asr_len\"] = df.asr.apply(lambda x: compute_asr_len(x))\n",
    "df[\"flow\"] = df.intent.apply(lambda x: get_flow_from_intent(x))\n",
    "df[\"suffix\"] = df.intent.apply(lambda x: get_suffix_from_intent(x))\n",
    "df[\"cleaned_asr\"] = df.asr.apply(lambda x: cleanASRservice.execute(x, delete_stopwords=False))\n",
    "df = compute_embeddings(df)\n",
    "tags = df['embeddings'].apply(pd.Series)\n",
    "features = tags.rename(columns = lambda x : 'embedding_feature_' + str(x))\n",
    "result = pd.concat([df, features], axis=1)\n",
    "X = result.drop(columns=[\"embeddings\", \"asr\", \"cleaned_asr\", \"intent\"], axis=1)\n",
    "\n",
    "# Extract text features -> convert to category\n",
    "cats = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "for col in cats:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "# Order features\n",
    "cols_when_model_builds = xgboost_model.get_booster().feature_names\n",
    "X = X[cols_when_model_builds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predict -> 0: No open, 1: Open -> Lo sÃ© por el label_encoder que he usado al entrenar el modelo\n",
    "y_pred = xgboost_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean output\n",
    "def handle_model_output(predictions: list) -> list:\n",
    "    return [True if pred == 1 else False for pred in predictions]\n",
    "\n",
    "output = handle_model_output(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
